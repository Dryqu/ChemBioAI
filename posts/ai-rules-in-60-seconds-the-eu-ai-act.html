<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Rules in 60 Seconds: The EU AI Act - ChemBio AI Insights</title>
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="../assets/css/style.css">
</head>
<body>
    <header>
        <div class="container nav-container">
            <a href="../index.html" class="logo">
                <div class="logo-icon">AI</div>
                <div class="logo-text">
                    <h1>ChemBio AI</h1>
                    <span>Insights</span>
                </div>
            </a>
            <nav>
                <a href="../index.html" class="btn" style="background: transparent; color: var(--primary-color); border: 1px solid var(--border-color);">Back to Home</a>
            </nav>
        </div>
    </header>

    <main>
        <article class="container" style="max-width: 800px; margin-top: 3rem; margin-bottom: 5rem;">
            <div class="article-header" style="text-align: center; margin-bottom: 3rem;">
                <span style="color: var(--accent-color); font-weight: 600; text-transform: uppercase; letter-spacing: 0.1em;">Global AI Trends</span>
                <h1 style="font-size: 2.5rem; margin: 1rem 0; color: var(--primary-color);">AI Rules in 60 Seconds: The EU AI Act</h1>
                <p style="color: #64748b;">December 10, 2025 • By Yi Qu</p>
            </div>

            <div class="article-body" style="font-size: 1.125rem; color: var(--text-color);">
                <p style="margin-bottom: 1.5rem;">The European Union’s AI Act is designed to harness the power of artificial intelligence while protecting people’s health, safety, and fundamental rights. The core philosophy is to stimulate innovation, but only “within certain boundaries”. I am sharing my key takeaways and perspectives below.</p>

                <h2 style="font-size: 1.75rem; color: var(--primary-color); margin-top: 2.5rem; margin-bottom: 1rem;">1. Broad Definition</h2>
                <p style="margin-bottom: 1.5rem;">The Act applies rules to a vast range of systems, defining AI broadly to include algorithms that “infers from inputs certain outputs”. This covers everything from the most simple linear regressions to complex large language models (LLMs) and image generators. Lawmakers intentionally cast this wide net because even simple algorithms have had a “devastating effect on people’s lives”.</p>
                <p style="margin-bottom: 1.5rem;">The rules apply to providers (those who develop AI and put it on the EU market) and deployers (organizations that use the AI for their own specified goals).</p>

                <h2 style="font-size: 1.75rem; color: var(--primary-color); margin-top: 2.5rem; margin-bottom: 1rem;">2. The Four Risk Categories</h2>
                <p style="margin-bottom: 1.5rem;">The rules become stricter as the potential harm increases:</p>
                <ul>
                    <li><strong>Prohibited Practices:</strong> Systems banned outright because they are “so dangerous to society”. This includes social scoring and classifying people based on sensitive characteristics (like race or sexual orientation).</li>
                    <li><strong>High-Risk AI Systems:</strong> Systems that bring huge societal benefits but carry high potential for harm. These must follow specific rules and are often found as safety components in physical products (like cars) or used in daily business tasks (such as handling employee data).</li>
                    <li><strong>Transparency Obligations:</strong> If AI-generated content (like deep fakes, text, or video) is not obviously fake to “an average human being,” the creator must state upfront that it is AI-generated.</li>
                    <li><strong>General Purpose AIs (GPAIs):</strong> For systems like major LLMs, the responsibility shifts between the provider and the deployer, depending on the purpose for which the end-user applies the AI.</li>
                </ul>

                <h2 style="font-size: 1.75rem; color: var(--primary-color); margin-top: 2.5rem; margin-bottom: 1rem;">3. Human Rights and Innovation</h2>
                <p style="margin-bottom: 1.5rem;">A key focus is protecting the 50 fundamental rights held by EU citizens, covering six categories, including dignity, freedoms, and equality. Providers and deployers must ensure their AI does not violate rights such as non-discrimination, privacy, or the right to a fair trial.</p>
                <p style="margin-bottom: 1.5rem;">To foster development, the Act includes an “AI sandbox” where developers can test new AIs, data, and algorithms, even if the systems don’t initially follow all rules strictly. The main condition is that “what happens in the sandbox stays in the sandbox”.</p>

                <h2 style="font-size: 1.75rem; color: var(--primary-color); margin-top: 2.5rem; margin-bottom: 1rem;">Why It Matters</h2>
                <p style="margin-bottom: 1.5rem;">This framework is revolutionary because it fundamentally links technological development to social accountability. By requiring compliance across a wide spectrum of algorithms and demanding the protection of fundamental rights from the design stage, the EU is making a clear statement: innovation must serve human rights, not erode them.</p>
            </div>
        </article>
    </main>

    <footer>
        <div class="container footer-content">
            <div>
                <p>&copy; 2025 ChemBio AI Insights. All rights reserved.</p>
            </div>
            <div>
                <p>Contact: <a href="mailto:chembioaiinsights@gmail.com" style="color: white;">chembioaiinsights@gmail.com</a></p>
            </div>
        </div>
    </footer>
</body>
</html>
